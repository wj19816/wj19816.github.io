# 账号注册及购买



![image-20201008203449910](/Users/didi/Library/Application Support/typora-user-images/image-20201008203449910.png)



![image-20201008203619080](/Users/didi/Desktop/wj19816.github.io/img/huawei-2.png)



登录实例：

```shell
ssh root@139.9.135.29 -p 22
ssh wj@139.9.135.29 -p 22
# The authenticity of host '139.9.135.29 (139.9.135.29)' can't be established.
# Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
```



### 修改安全组

![image-20201008223423605](/Users/didi/Desktop/wj19816.github.io/img/huawei-3.png)



# 基本配置

### 修改主机名称

```shell
hostname #查看主机名
hostnamectl set-hostname lwcloud #修改主机名
#然后重启命令行即可看到
vim /etc/hosts #可能需要修改配置文件？
```



## 新建用户

```shell
sudo adduser test_name #创建普通用户+密码
ls /home/ #查看用户是否创建成功

su -l test_name #切换用户
exit #退出用户

groups test_name #查看用户组
sudo usermod -G sudo test_name #将新建用户加入sudo用户组

sudo deluser test_name #删除用户
```





## 环境配置

```shell
# 查看系统版本
uname -a
# Linux ecs-kc1-large-2-linux-20201008202853 4.15.0-70-generic #79-Ubuntu SMP Tue Nov 12 10:36:10 UTC 2019 aarch64 aarch64 aarch64 GNU/Linux
```



### pip

```shell
wget https://bootstrap.pypa.io/get-pip.py
python get-pip.py
pip -V
# pip 20.2.3 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)
```



## Anaconda

```shell
#官网：https://www.anaconda.com/products/individual
#系统版本为aarch64，使用以下链接：
#https://github.com/Archiconda/build-tools/releases
#如果使用root用户安装：
scp Archiconda3-0.2.3-Linux-aarch64.sh root@139.9.135.29:/root/anaconda/
bash Archiconda3-0.2.3-Linux-aarch64.sh
#修改默认安装位置：/usr/local/anaconda3
vim /etc/profile
#在最后一行加入配置环境变量
export PATH=/usr/local/anaconda3/bin:$PATH
source /etc/profile
```

```shell
#创建虚拟环境
conda create -n tf python=3.6 -y #新建
source activate tf #激活
source deactivate tf #退出

conda remove -n tf --all #删除

#查看所有虚拟环境
conda info --env
```

```shell
#更改下载镜像
conda config --add channels https://anaconda.org/
conda config --set show_channel_urls yes
```



如果出现报错：`Solving environment: failed`

```shell
#源切换回默认
conda config --remove-key channels
#更新base环境
conda update -n base conda
```





### python

```shell
#查看是否存在python及版本
python
# Python 2.7.15+ (default, Oct  7 2019, 17:39:04)
# [GCC 7.4.0] on linux2
python3
# Python 3.6.9 (default, Nov  7 2019, 10:44:02)
# [GCC 8.3.0] on linux

#更换默认python版本
which python3
#/usr/bin/python3
sudo unlink /usr/bin/python
sudo ln -s /usr/bin/python3 /usr/bin/python
```



### R

https://zhuanlan.zhihu.com/p/82105271

```shell
sudo apt-get update
sudo apt-get install r-base
sudo -i R

R
# R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
```



### jupyter notebook

```shell
pip install --upgrade pip
pip install jupyter

apt install jupyter-core
apt install jupyter-notebook
jupyter-notebook

#在自己浏览器打开jupyter
ssh -L 8888:localhost:8888 wj@139.9.135.29 

#配置密码
jupyter notebook --generate-config
# /root/.jupyter/jupyter_notebook_config.py

python
from IPython.lib import passwd
passwd()

vim /root/.jupyter/jupyter_notebook_config.py

c.NotebookApp.ip='*'
c.NotebookApp.password = u''
c.NotebookApp.open_browser = False
c.NotebookApp.port = 8888 #随便指定一个端口
c.IPKernelApp.pylab = 'inline'  #这个可能没有，找不到就不用管了
c.NotebookApp.notebook_dir = '/home/'   #设置jupyter启动后默认的文件夹

#挂起jupyter
nohup jupyter notebook --allow-root --no-browser --port 8888 1>nb.log 2>&1 &
# [1] 27392

#查看进程号并杀死进程
ps aux | grep jupyter
kill -9 27392
```



```shell
#安装R内核
#sudo aptitude install libssl-dev
install.packages('devtools') #如果失败依次安装依赖包
devtools::install_github('IRkernel/IRkernel')
IRkernel::installspec()
```



```shell
# 安装nbextension插件
pip install jupyter_contrib_nbextensions
jupyter contrib nbextension install --user
```



### hadoop

```shell
#最好在虚拟环境中安装，防止安装出错破坏系统
conda create -n hadoop python=3.7 -y #新建
source activate hadoop #进入虚拟环境
source deactivate hadoop #退出
```

下载并安装java和hadoop的安装包：
```shell
#java
wget https://www.oracle.com/webapps/redirect/signon?nexturl=https://download.oracle.com/otn/java/jdk/8u261-b13/a4634525489241b9a9e1aa73d9e118e6/jdk-8u261-linux-arm64-vfp-hflt.tar.gz

which java
#/usr/bin/java

scp jdk-8u261-linux-arm64-vfp-hflt.tar.gz root@139.9.135.29:/usr/local/java/
tar -xvf jdk-8u261-linux-arm64-vfp-hflt.tar.gz -C /usr/local/java

vim /etc/profile
#在尾部添加下列：
export JAVA_HOME=/usr/local/java/jdk1.8.0_261
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export PATH=.:$JAVA_HOME/bin:$PATH

source /etc/profile
```

```shell
#hadoop
mkdir /usr/local/hadoop
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.10.1/hadoop-2.10.1.tar.gz
tar -xvf hadoop-2.10.1.tar.gz -C /usr/local/hadoop

vim /etc/profile
#在尾部添加下列：
export HADOOP_HOME=/usr/local/hadoop/hadoop-2.10.1
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"
export PATH=.:${JAVA_HOME}/bin:${HADOOP_HOME}/bin:$PATH

source /etc/profile
```

配置环境

```shell
#参考：https://www.jianshu.com/p/2d44b95ef802

#设置IP映射
vim /etc/hosts
#在最后加上 139.9.135.29 lwcloud  #有可能有问题？

#关闭防火墙
sudo ufw status #查看状态
sudo ufw disable #关闭
#sudo ufw enable #开启

```

![image-20201009210426049](/Users/didi/Desktop/wj19816.github.io/img/hadoop.png)

设置免密登陆，是为了防止以后启动hadoop时，每次启动一个节点都需要输入密码。分别执行如下命令：

```shell
#设置免密登录
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
# Generating public/private dsa key pair.

# Your identification has been saved in /root/.ssh/id_dsa.
# Your public key has been saved in /root/.ssh/id_dsa.pub.
# The key fingerprint is:
# SHA256:X1mSNbPPV+TqBFg+Duhm4anRpT9cKhd/zQfXsTubvWs root@lwcloud
# The key's randomart image is:
# +---[DSA 1024]----+
# |            . + .|
# |         . + o * |
# |        o + * o.o|
# |       + = o * +=|
# |      . S . = +.*|
# |       = + * o =o|
# |      . . B . oo+|
# |         o . . E*|
# |              .=+|
# +----[SHA256]-----+
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys

#用root用户设置"/etc/ssh/sshd_config"的内容
vim /etc/ssh/sshd_config
#修改配置如下：
RSAAuthentication yes # 启用 RSA 认证
PubkeyAuthentication yes # 启用公钥私钥配对认证方式
AuthorizedKeysFile .ssh/authorized_keys # 公钥文件路径（和上面生成的文件同）

#重启ssh服务使配置生效：
service sshd restart
```

##### 修改 hadoop-env.sh

Hadoop运行在JDK之上，原本hadoop-env.sh文件中使用的是相对路径，但是在一些环境中会报错，因此此处修改为绝对路径。

```shell
find -name hadoop-env.sh
#/usr/local/hadoop/hadoop-2.10.1/etc/hadoop/hadoop-env.sh

vim hadoop-env.sh

#将export JAVA_HOME=${JAVA_HOME}改为：
export JAVA_HOME=/usr/local/java/jdk1.8.0_261

#在<configuration></configuration>之间添加：
export HADOOP_NAMENODE_OPTS=" -Xms1024m -Xmx2014m -XX:+UseParallelGC"
export HADOOP_DATANODE_OPTS=" -Xms1024m -Xmx2014m"
export HADOOP_LOG_DIR=/data/logs/hadoop   #记得在命令行建立这个文件夹
export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"  
```

##### 修改 core-site.xml

```shell
vim core-site.xml

#在<configuration></configuration>之间添加以下内容：
<property>
        <name>hadoop.tmp.dir</name>
        <value>/root/hadoop/tmp</value>
        <description>Abase for other temporary directories.</description>
   </property>
   <property>
        <name>fs.default.name</name>
        <value>hdfs://lwhadoop:8050</value>
</property>
```

##### 修改hdfs-site.xml文件

执行`vim hdfs-site.xml`,修改hdfs配置，在`<configuration></configuration>`之间添加以下内容：



```shell
vim hdfs-site.xml
mkdir -vp /root/hadoop/dfs/name
mkdir -vp /root/hadoop/dfs/data

#在<configuration></configuration>之间添加以下内容：
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:///root/hadoop/dfs/name</value>
</property>
<property>
<name>dfs.dataenode.data.dir</name>
<value>file:///root/hadoop/dfs/data</value>
</property>
```



##### 修改mapred-site.xml文件

```shell
cp mapred-site.xml.template mapred-site.xml
mkdir -vp /root/hadoop/var

#复制mapred-site.xml.template文件，编辑mapred-site.xml文件，加入以下内容
<property>
    <name>mapred.job.tracker</name>
    <value>lwhadoop:8051</value>
</property>
<property>
      <name>mapred.local.dir</name>
       <value>/root/hadoop/var</value>
</property>
<property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
</property>
```

#### 初始化并启动hadoop

```shell
#初始化
hadoop namenode -format
```

初始化成功后，可以在/root/hadoop/dfs/name 目录下(该路径在hdfs-site.xml文件中进行了相应配置，并新建了该文件夹)新增了一个current 目录以及一些文件。 

![image-20201009210752805](/Users/didi/Desktop/wj19816.github.io/img/hadoop-s.png)

```shell
#启动
sh /usr/local/hadoop/hadoop-2.10.1/sbin/start-dfs.sh

This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
20/10/09 21:15:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting namenodes on [lwhadoop]
root@lwhadoop's password:
lwhadoop: namenode running as process 10094. Stop it first.
root@localhost's password:
localhost: datanode running as process 10304. Stop it first.
Starting secondary namenodes [0.0.0.0]
root@0.0.0.0's password:
0.0.0.0: starting secondarynamenode, logging to /data/logs/hadoop/hadoop-root-secondarynamenode-lwcloud.out
20/10/09 21:16:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
starting yarn daemons
resourcemanager running as process 10561. Stop it first.
root@localhost's password:
localhost: nodemanager running as process 10928. Stop it first.
```



#### 报错----未解决

```shell
tar -xvf hadoop-native-64.tar -C /usr/local/hadoop/hadoop-2.10.1/lib/native
#可能解决方法：https://my.oschina.net/itblog/blog/270360
```



### tensorflow 2.0----未解决

```shell
#https://zhuanlan.zhihu.com/p/109318004
#https://blog.csdn.net/AIHUBEI/article/details/105045715

#最好在虚拟环境中安装，防止安装出错破坏系统
conda create -n tf37 python=3.7 -y #新建
source activate tf37 #激活
source deactivate tf37 #退出

#查找可用的安装包：https://anaconda.org/
#复制想下载的安装包命令即可
conda install -c hesi_m tensorflow

#复制安装包-----没成功
scp tensorflow-2.1.0-cp37-none-linux_aarch64.whl root@139.9.135.29:/root/tf/
sudo python3 -m pip install tensorflow-2.3.0-cp37-none-linux_aarch64.whl

```







## 常用操作

- 文件传输

```shell
#从本地传到服务器
scp local.file root@139.9.135.29:/root/
#从服务器传到本地
scp root@139.9.135.29:/root/ local.file
scp -r root@139.9.135.29:/root/ local.folder  #-r:复制文件夹
```



- 文件下载

```shell
wget -c http://.....  #-c：可以断点续传
```

